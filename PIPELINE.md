# Collateral Bio – Full Pipeline Walkthrough

This guide walks you through the **exact commands** to run the full pipeline using your **matrix file** (`KB_and_Pub_Recur_per_cancer.csv`) and **fusion CSVs** (`known_fusions.csv`, `novel_fusions.csv`).

**Quick start:** If those files are in `data/`, ARCHS4 is in `data/expression_data/human_matrix.h5`, and `.env` has `GEMINI_API_KEY`, run:

```bash
python run_pipeline.py
```

Otherwise, follow the steps below.

---

## 1. Prerequisites

- **Python 3.8+**
- **Data files** in `data/`:
  - **Matrix:** `data/KB_and_Pub_Recur_per_cancer.csv` (or `disease_matrix_known.csv`) – fusions × cancer types
  - **Fusion CSVs:** `data/known_fusions.csv` and/or `data/novel_fusions.csv` – fusion lists for targeting
  - **ARCHS4 (Expert Agent):** `data/expression_data/human_matrix.h5` – normal vs cancer expression
- **`.env`** in project root with `GEMINI_API_KEY=...` (for Expert Agent AI)

---

## 2. One-time setup

From the project root (`collateral_bio_core/`):

```bash
# Create and activate venv (Windows)
python -m venv venv
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

## 3. (Optional) Refresh fusion CSVs from Excel

If you use `Recurrent_table.xlsx` and want to regenerate `known_fusions.csv` / `novel_fusions.csv`:

```bash
python utils/split_excel.py
```

This reads `data/Recurrent_table.xlsx` and writes the fusion CSVs and matrix CSVs (e.g. `KB_and_Pub_Recur_per_cancer.csv`) into `data/`.

---

## 4. Place ARCHS4 matrix (Expert Agent)

Download **human_matrix.h5** from [ARCHS4](https://maayanlab.cloud/archs4/) and put it here:

```
data/expression_data/human_matrix.h5
```

Create the folder if needed:

```bash
mkdir data\expression_data
# then copy human_matrix.h5 into it
```

---

## 5. Run the full pipeline

**Option A – Single command (all steps):**

```bash
python run_pipeline.py
```

This runs, in order:

1. **Mine** – NCBI Cas13d search → `data/raw_sequences/search_YYYYMMDD_HHMMSS.fasta`
2. **Matchmaker** – enzymes × fusions (using your matrix + fusion CSVs) → `lead_candidates.csv`
3. **Expert Agent** – cancer-only filter, safety, AI → `dashboard.html`, `lead_candidates_filtered.csv`

---

**Option B – Step-by-step commands:**

**Step 1 – Mine Cas13d enzymes (NCBI):**

```bash
python -c "from modules.mining.ncbi_miner import EnzymeMiner; m = EnzymeMiner('data/raw_sequences'); m.search_and_fetch(query='Cas13d NOT synthetic construct', max_results=50)"
```

**Step 2 – Matchmaker (enzymes vs fusions):**

Uses latest `data/raw_sequences/search_*.fasta`, `data/known_fusions.csv`, and `data/KB_and_Pub_Recur_per_cancer.csv`.

```bash
python modules/matchmaker.py
```

**Step 3 – Expert Agent (filter + safety + AI):**

Reads `lead_candidates.csv`, uses ARCHS4 for normal/cancer filtering, then AI commentary.

```bash
python modules/analysis/expert_agent.py
```

---

## 6. Choosing fusion CSV (known vs novel)

- **Known fusions (default):** `data/known_fusions.csv`
- **Novel fusions:** set env before running matchmaker / pipeline:

```bash
set TARGET_FUSIONS_CSV=novel_fusions.csv
python modules/matchmaker.py
```

Or for the full pipeline:

```bash
set TARGET_FUSIONS_CSV=novel_fusions.csv
python run_pipeline.py
```

On macOS/Linux use `export TARGET_FUSIONS_CSV=novel_fusions.csv` instead of `set`.

---

## 7. Outputs

| Step            | Output                                 | Description                                        |
|-----------------|----------------------------------------|----------------------------------------------------|
| Mine            | `data/raw_sequences/search_*.fasta`    | Cas13d sequences from NCBI                         |
| Family Grouping | `data/mined_sequences/family_grouped_*.fasta` | Sequences grouped by homology (SN01_001, etc.)   |
| Family Grouping | `data/mined_sequences/family_manifest_*.csv`  | Mapping: new_id, original_id, hepn_count          |
| Matchmaker      | `lead_candidates.csv`                  | Enzyme–fusion pairs (ranked)                       |
| Expert Agent    | `lead_candidates_filtered.csv`         | Cancer-only, absent-in-normal filtered leads       |
| Expert Agent    | `dashboard.html`                       | Dashboard of filtered candidates (open in browser) |

---

## 8. Inspect ARCHS4 normal/cancer classification

To verify that ARCHS4 samples are correctly classified as normal vs cancer (and tune keywords if needed):

```bash
python utils/inspect_archs4_metadata.py
```

This prints unique `source_name_ch1` labels and their classification (normal / cancer / unknown).

## 9. Env options for Expert Agent filter

- **`ENRICHMENT_FACTOR`** (default `2.0`): organ-specific mode requires `cancer_mean ≥ enrichment_factor × normal_mean`.
- **`USE_ORGAN_SPECIFIC`** (default `1`): use organ-specific normal/cancer and enrichment when fusions have associated cancers (from KB_and_Pub / novel_Recur). Set to `0` to use global normal/cancer only.

## 10. Post-filter (Cas13/Type VI HEPN)

After running the **Autonomous Prospector** for a period (e.g. one week), filter the collected `deep_hits_*.fasta` files using canonical Pfam HEPN domain criteria:

**One-time setup – fetch Pfam HEPN HMM:**

```bash
python utils/fetch_pfam_hepn.py
```

**Run the post-filter:**

```bash
python modules/mining/hepn_filter.py
```

Options:
- `--input-dir data/raw_sequences` – directory with deep_hits FASTA files
- `--glob "deep_hits_*.fasta"` – input file pattern
- `--require-motif` – also require R.{4,6}H motif topology (100–600 aa spacing)
- `--output my_filtered` – output basename

Outputs:
- `data/raw_sequences/cas13_filtered_YYYYMMDD.fasta` – sequences passing dual-HEPN filter
- `data/raw_sequences/cas13_filter_report_YYYYMMDD.tsv` – per-sequence report (hepn_hits, e_values, passed)

Requires `pyhmmer` (or system HMMER). The filter uses Pfam PF05168 (HEPN) and requires at least 2 domain hits per sequence (E-value ≤ 1e-5).

---

## 12. Family Grouping (mined sequences)

After collecting mined sequences in `data/mined_sequences/` (e.g. `deep_hits_*.fasta`), group them into families by homology (ESM-2) and HEPN count. Output uses naming convention `SN01_001`, `SN01_002`, etc.

**Prerequisites:** `torch`, `transformers` (for ESM-2), `scipy` (for clustering).

```bash
python modules/mining/family_grouper.py
```

Options:
- `--input-dir data/mined_sequences` – directory with FASTA files (default: `data/mined_sequences`)
- `--output-dir` – output directory (default: same as input)
- `--threshold 0.7` – cosine similarity threshold for same family (default 0.7)
- `--prefix SN` – family ID prefix
- `--glob "*.fasta"` – glob pattern for input files

Env vars: `FAMILY_SIMILARITY_THRESHOLD`, `FAMILY_PREFIX`, `FAMILY_INPUT_DIR`

Outputs:
- `data/mined_sequences/family_grouped_YYYYMMDD.fasta` – sequences renamed (e.g. `>SN01_001`)
- `data/mined_sequences/family_manifest_YYYYMMDD.csv` – mapping: new_id, original_id, hepn_count, family_id, member_index

---

## 13. Troubleshooting

- **"No module named 'Bio'"** → `pip install biopython` (or `pip install -r requirements.txt`).
- **"ARCHS4 required"** → Add `data/expression_data/human_matrix.h5` (see step 4).
- **"Disease matrix file not found"** → Ensure `data/KB_and_Pub_Recur_per_cancer.csv` exists (or `disease_matrix_known.csv`).
- **"Target file not found"** → Ensure `data/known_fusions.csv` (or `novel_fusions.csv`) exists; run `utils/split_excel.py` if needed.
- **No fusions pass filter** → Run `utils/inspect_archs4_metadata.py` to check normal/cancer labels. Ensure fusions have associated cancers (matchmaker uses `KB_and_Pub_Recur_per_cancer`). Try lowering `ENRICHMENT_FACTOR` or raising `CANCER_MIN_TPM`.
